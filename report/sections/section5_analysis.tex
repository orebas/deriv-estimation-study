\section{Results and Analysis}
\label{sec:results}

After a comprehensive evaluation across a range of methods, three distinct dynamical systems, and a sweep of noise levels, clear patterns emerge. Performance was analyzed in two regimes: a "low-noise" regime ($\le 0.1\%$ noise) where precision is paramount, and a "high-noise" regime (1-2\% noise) where robustness is key.

The table below summarizes the performance of contender methods that demonstrated full data coverage for derivative orders 1 through 5. Methods are sorted by their overall average rank, giving equal weight to performance in both low- and high-noise regimes. Averages are calculated over orders 1-5 (excluding order 0 function approximation, focusing on actual derivative estimation).

% AUTO-GENERATED by gemini-analysis/generate_exploratory_tables.py
% To regenerate: ./scripts/04_generate_tables.sh
% Alternative versions (orders 3, 7) available as tab_summary_order{3,7}.tex
\input{../build/tables/publication/tab_summary_order5.tex}

\textbf{Our principal findings are as follows:}

\begin{enumerate}
    \item \textbf{Gaussian Process Regression (GPR) is the most robust and accurate method overall.} The Julia GPR implementation (\texttt{GP-TaylorAD-Julia}) and the improved Python variants (\texttt{GP-RBF-*}) are the clear winners, consistently occupying the top ranks in both low and high-noise regimes.
    \item \textbf{The optimal method depends on the noise level and derivative order.} While GPR is the best all-arounder, splines like \texttt{Spline-Dierckx-5} offer excellent precision in low-noise environments, making them a top choice for cleaner data, particularly at modest derivative orders. In the high-noise regime, the filtering-based \texttt{Savitzky-Golay} provides a computationally cheap and highly effective alternative, ranking solidly in the top half of contenders.
    \item \textbf{Theoretical limits matter.} Many common low-degree spline methods are, by definition, incapable of representing high-order derivatives, limiting their applicability.
    \item \textbf{Dedicated packages offer convenient and robust options, but need a differentiation backend.}   Purpose built libraries are convenient, but our strongest results come from extending them with either analytic or auto-differentiated derivatives of smoothed data.  For this to work best, the library should ideally produce very smooth models, and either expose some of the model internals or be amenable to AD.

\end{enumerate}

These findings are illustrated in the accompanying visualizations.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.9\textwidth]{high_noise_fit_comparison.png}
\caption{\textbf{High-Noise Performance (2\% noise, 4th derivative).} Three-panel comparison showing: (top) noisy input data as black points against gray ground truth, emphasizing the challenging signal-to-noise environment; (middle) derivative estimates from four methods representing different algorithmic approaches; (bottom) estimation errors revealing where each method succeeds or fails. The figure shows \texttt{GP-TaylorAD-Julia}, \texttt{Fourier-GCV}, \texttt{Spline-Dierckx-5}, and \texttt{Fourier-Continuation-Python}. The error panel reveals that all methods struggle at the trajectory boundaries.}
\label{fig:high_noise_comp}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.9\textwidth]{low_noise_fit_comparison.png}
\caption{\textbf{Low-Noise Precision (1e-6 noise, 5th derivative).} Three-panel comparison in a low-noise regime: (top) noisy data points (black) are nearly imperceptible against gray ground truth; (middle) 5th-order derivative estimates from four methods; (bottom) estimation errors showing clear performance hierarchy. The figure compares \texttt{GP-TaylorAD-Julia}, \texttt{SavitzkyGolay-Adaptive}, \texttt{Spline-Dierckx-5}, and \texttt{SavitzkyGolay-Fixed}. Even in this clean environment, high-order differentiation remains extremely challenging, with significant performance differences between methods.}
\label{fig:low_noise_comp}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.9\textwidth]{heatmap_orders_1to5.png}
\caption{\textbf{Performance Degradation with Increasing Derivative Order (Orders 1-5).} This heatmap shows the mean nRMSE for top methods covering derivative orders 1-5, averaged across all noise levels. Methods are ranked by their average performance across these orders. The visualization shows that \texttt{GP-TaylorAD-Julia} maintains low error across all orders, while other methods like \texttt{Spline-Dierckx-5} and \texttt{ButterworthSpline\_Python} are highly accurate for low orders but degrade significantly as the order increases. High-order derivatives (orders 6-7) are analyzed separately in Appendix~\ref{app:high_order}.}
\label{fig:heatmap}
\end{figure}

\FloatBarrier
The subsequent subsections detail the methodology and analysis that support these conclusions, starting with an explanation of our ranking approach.

\subsection{Ranking Methodology}
To produce the final summary table, we followed a two-step ranking process:
\begin{enumerate}
    \item \textbf{Per-Cell Ranking}: For each individual experimental cell—defined by a unique combination of \texttt{(ODE\_system, noise\_level, derivative\_order)}—we ranked the contender methods against each other based on their mean \texttt{nRMSE} (averaged across the 10 trials for that cell).
    \item \textbf{Averaging Ranks}: We then calculated the final "Avg. Rank" for each method by averaging these per-cell ranks across two distinct regimes:
    \begin{itemize}
        \item \textbf{Low-Noise Regime}: Averaged across noise levels below 1\% (\texttt{1e-8}, \texttt{1e-6}, \texttt{1e-4}, and \texttt{1e-3}).
        \item \textbf{High-Noise Regime}: Averaged across noise levels of 1\% and above (\texttt{0.01} and \texttt{0.02}).
    \end{itemize}
\end{enumerate}
This methodology ensures that the final rank is a robust measure of a method's performance across a wide variety of conditions, and it prevents a single outlier or a particularly favorable test case from dominating the results.

\subsection{Performance Degradation by Derivative Order}
A clear pattern emerging from the data is the systematic degradation of performance as the derivative order increases. This is an expected consequence of the ill-posed nature of differentiation. We can characterize this trend in several phases:
\begin{itemize}
    \item \textbf{Orders 0-2 (Low-Order):} In this regime, most contender methods perform well, and the performance differences between them are relatively modest, particularly in low-noise scenarios. The task of smoothing or finding a first or second derivative is not challenging enough to create significant separation between the top methods.
    \item \textbf{Orders 3-5 (Mid-Order):} This is the regime where a clear separation emerges. The task becomes significantly more challenging, and methods without sophisticated noise handling begin to struggle. The performance of GPR and the stronger spectral methods remains high, while simpler spline- and filter-based methods see a substantial drop in accuracy.
    \item \textbf{Orders 6-7 (High-Order):} This regime represents an extreme challenge. Only a very small subset of methods, primarily GPR, are able to produce a usable estimate, and even their errors are significant. For most other methods, the error in this regime constitutes a catastrophic failure. Derivative order is clearly the dominant factor in the difficulty of the estimation problem.
\end{itemize}

Figure~\ref{fig:small_multiples} provides a comprehensive visual illustration of this systematic degradation. The figure shows performance across all eight derivative orders for the top seven methods, clearly demonstrating how error increases with order and how different methods respond to increasing noise levels at each order.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.95\textwidth]{small_multiples_grid.png}
\caption{\textbf{Performance Across All Derivative Orders.} This 4×2 grid shows nRMSE vs noise level for 6 representative methods at each derivative order (0--7). Each panel illustrates the systematic degradation of performance as order increases. Note how GP-TaylorAD-Julia (top performer) maintains relatively stable performance across all orders, while other methods show dramatic degradation beyond order 3.}
\label{fig:small_multiples}
\end{figure}

\FloatBarrier
% Computational efficiency considerations moved to Practitioner's Guide in Conclusion
% Removed PyNumDiff analysis subsection - methods are included in main results
