# Repository Organization

This document describes the repository structure and file organization for the derivative estimation study.

## Directory Structure

```
derivative_estimation_study/
‚îú‚îÄ‚îÄ methods/              # Method implementations (the "what")
‚îÇ   ‚îú‚îÄ‚îÄ julia/           # Julia method implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common.jl    # Shared utilities and derivative computation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adaptive/    # AAA rational approximation methods
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ filtering/   # Savitzky-Golay and filtering methods
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gp/          # Gaussian process methods
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ regularization/  # Trend filtering and regularization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ spectral/    # Fourier and spectral methods
‚îÇ   ‚îî‚îÄ‚îÄ python/          # Python method implementations
‚îÇ       ‚îú‚îÄ‚îÄ common.py    # Shared utilities and base classes
‚îÇ       ‚îú‚îÄ‚îÄ adaptive/    # AAA with adaptive hyperparameters
‚îÇ       ‚îú‚îÄ‚îÄ filtering/   # Filtering and smoothing methods
‚îÇ       ‚îú‚îÄ‚îÄ gp/          # Gaussian process methods
‚îÇ       ‚îú‚îÄ‚îÄ rational/    # Rational approximation methods
‚îÇ       ‚îú‚îÄ‚îÄ spectral/    # Fourier and spectral methods
‚îÇ       ‚îî‚îÄ‚îÄ splines/     # Spline-based methods
‚îÇ
‚îú‚îÄ‚îÄ src/                  # Study runners and shared infrastructure (the "how")
‚îÇ   ‚îú‚îÄ‚îÄ julia_methods_integrated.jl   # Wrapper to call Julia methods
‚îÇ   ‚îú‚îÄ‚îÄ pilot_study.jl                # Quick pilot study runner
‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_study.jl        # Full benchmark study runner
‚îÇ   ‚îú‚îÄ‚îÄ ground_truth.jl               # Test function generation
‚îÇ   ‚îú‚îÄ‚îÄ noise_model.jl                # Noise generation
‚îÇ   ‚îî‚îÄ‚îÄ hyperparameter_selection.jl   # Julia hyperparameter utilities
‚îÇ
‚îú‚îÄ‚îÄ python/              # Python infrastructure and build scripts
‚îÇ   ‚îú‚îÄ‚îÄ python_methods_integrated.py  # Wrapper to call Python methods
‚îÇ   ‚îú‚îÄ‚îÄ generate_comprehensive_plots.py  # Per-method and per-order visualizations
‚îÇ   ‚îú‚îÄ‚îÄ generate_paper_tables.py      # LaTeX table generation
‚îÇ   ‚îú‚îÄ‚îÄ generate_additional_figures.py  # Supplemental figures
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameters.py            # Adaptive hyperparameter selection (shared)
‚îÇ   ‚îú‚îÄ‚îÄ baryrat_jax.py                # JAX wrapper for AAA (shared)
‚îÇ   ‚îú‚îÄ‚îÄ tvregdiff.py                  # TVRegDiff implementation (shared)
‚îÇ   ‚îú‚îÄ‚îÄ jax_derivatives.py            # JAX automatic differentiation utilities
‚îÇ   ‚îî‚îÄ‚îÄ matern_optimized.py           # Optimized Matern kernel for GP
‚îÇ
‚îú‚îÄ‚îÄ report/              # LaTeX source (pure source, no outputs)
‚îÇ   ‚îú‚îÄ‚îÄ paper.tex        # Main paper structure and abstract
‚îÇ   ‚îú‚îÄ‚îÄ sections/        # Paper content sections
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section1_introduction.tex
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section3_problem.tex
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section4_methodology.tex
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section5_methods.tex
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section6_results.tex
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section7_discussion.tex
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section8_recommendations.tex
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section9_limitations.tex
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ section10_conclusion.tex
‚îÇ   ‚îî‚îÄ‚îÄ references.bib   # Bibliography
‚îÇ
‚îú‚îÄ‚îÄ build/               # All generated outputs (git-ignored)
‚îÇ   ‚îú‚îÄ‚îÄ results/         # Raw data from studies
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pilot/       # Pilot study results (JSON)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ comprehensive/  # Full study results
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ comprehensive_summary.csv  # ‚≠ê SINGLE SOURCE OF TRUTH
‚îÇ   ‚îú‚îÄ‚îÄ figures/         # Generated plots
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ publication/ # Main paper figures (PDF/PNG)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ supplemental/  # Supplemental figures
‚îÇ   ‚îú‚îÄ‚îÄ tables/          # Generated LaTeX tables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ publication/ # Main paper tables
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ supplemental/  # Supplemental tables
‚îÇ   ‚îú‚îÄ‚îÄ tex/             # LaTeX build artifacts (.aux, .log, .out, .toc)
‚îÇ   ‚îî‚îÄ‚îÄ paper/           # Final compiled paper
‚îÇ       ‚îî‚îÄ‚îÄ paper.pdf    # üìÑ FINAL OUTPUT
‚îÇ
‚îú‚îÄ‚îÄ scripts/             # Build pipeline automation
‚îÇ   ‚îú‚îÄ‚îÄ 01_run_pilot.sh          # Step 1: Quick validation
‚îÇ   ‚îú‚îÄ‚îÄ 02_run_comprehensive.sh  # Step 2: Full benchmark
‚îÇ   ‚îú‚îÄ‚îÄ 03_generate_figures.sh   # Step 3: Create all plots
‚îÇ   ‚îú‚îÄ‚îÄ 04_generate_tables.sh    # Step 4: Create LaTeX tables
‚îÇ   ‚îú‚îÄ‚îÄ 05_compile_paper.sh      # Step 5: Build PDF
‚îÇ   ‚îú‚îÄ‚îÄ build_all.sh             # Run entire pipeline
‚îÇ   ‚îî‚îÄ‚îÄ clean.sh                 # Remove all build artifacts
‚îÇ
‚îú‚îÄ‚îÄ docs/                # Documentation and analysis
‚îÇ   ‚îú‚îÄ‚îÄ BUG_ANALYSIS_ZERO_DERIVATIVES.md  # Step-function bug investigation
‚îÇ   ‚îú‚îÄ‚îÄ METHOD_API_SPEC.md       # Method interface specification
‚îÇ   ‚îú‚îÄ‚îÄ METHOD_CATALOG.md        # Complete method catalog
‚îÇ   ‚îî‚îÄ‚îÄ PHASE2_PROGRESS.md       # Development progress tracking
‚îÇ
‚îú‚îÄ‚îÄ Project.toml         # Julia project dependencies
‚îú‚îÄ‚îÄ Manifest.toml        # Julia dependency lock file
‚îú‚îÄ‚îÄ pyproject.toml       # Python project configuration
‚îú‚îÄ‚îÄ requirements.lock    # Python dependency lock file
‚îú‚îÄ‚îÄ uv.lock              # UV package manager lock file
‚îî‚îÄ‚îÄ README.md            # Main repository documentation
```

## Data Flow

The repository follows a **single-source-of-truth** data flow:

```
1. Study Runners (src/*.jl)
   ‚îî‚îÄ> Generate noisy data + evaluate methods
       ‚îî‚îÄ> Write JSON results to build/results/

2. Comprehensive Study
   ‚îî‚îÄ> Aggregate all results into CSV
       ‚îî‚îÄ> build/results/comprehensive/comprehensive_summary.csv  ‚≠ê

3. Visualization Pipeline
   ‚îú‚îÄ> python/generate_comprehensive_plots.py
   ‚îÇ   ‚îî‚îÄ> Reads CSV ‚Üí Generates per-method and per-order plots
   ‚îÇ       ‚îî‚îÄ> build/figures/publication/*.pdf
   ‚îÇ       ‚îî‚îÄ> build/figures/supplemental/*.pdf
   ‚îÇ
   ‚îú‚îÄ> python/generate_paper_tables.py
   ‚îÇ   ‚îî‚îÄ> Reads CSV ‚Üí Generates LaTeX tables
   ‚îÇ       ‚îî‚îÄ> build/tables/publication/*.tex
   ‚îÇ
   ‚îî‚îÄ> python/generate_additional_figures.py
       ‚îî‚îÄ> Reads CSV ‚Üí Generates specialized figures
           ‚îî‚îÄ> build/figures/publication/*.pdf

4. LaTeX Compilation (report/paper.tex)
   ‚îú‚îÄ> \input{build/tables/publication/*.tex}
   ‚îú‚îÄ> \includegraphics{build/figures/publication/*.pdf}
   ‚îî‚îÄ> Build artifacts ‚Üí build/tex/
   ‚îî‚îÄ> Final PDF ‚Üí build/paper/paper.pdf  üìÑ
```

## Key Principles

### 1. **Pure Source vs. Generated Outputs**
- **Source directories** (`methods/`, `src/`, `python/`, `report/`, `scripts/`): Version controlled
- **Build directory** (`build/`): Git-ignored, fully regenerable

### 2. **Single Source of Truth**
- **Data**: `build/results/comprehensive/comprehensive_summary.csv`
- **Plots**: All read from the CSV, not from individual method results
- **Tables**: All generated from the CSV

### 3. **Method Organization**
- **Implementation**: In `methods/julia/` or `methods/python/` organized by category
- **Shared utilities**:
  - Julia: `methods/julia/common.jl`
  - Python: `methods/python/common.py`, `python/*.py` (for cross-category shared code)
- **Study infrastructure**: In `src/` (Julia) or `python/` (Python build scripts)

### 4. **Clear Separation**
- **Methods** (what): `methods/` - Pure algorithm implementations
- **Studies** (how): `src/` - How to run and evaluate methods
- **Infrastructure** (tools): `python/` - Shared utilities and build pipeline
- **Paper** (presentation): `report/` - LaTeX source
- **Outputs** (results): `build/` - All generated content

## How to Edit

### To modify paper text:
```bash
# Edit the relevant section file
vim report/sections/section6_results.tex

# Rebuild the paper
./scripts/05_compile_paper.sh

# Output: build/paper/paper.pdf
```

### To add a new method:
```julia
# 1. Create implementation
touch methods/julia/filtering/my_new_method.jl

# 2. Add to method list
vim src/julia_methods_integrated.jl

# 3. Re-run study
./scripts/02_run_comprehensive.sh
```

### To modify plots:
```python
# Edit plot generation
vim python/generate_comprehensive_plots.py

# Regenerate figures
./scripts/03_generate_figures.sh

# Output: build/figures/publication/*.pdf
```

### To clean and rebuild everything:
```bash
./scripts/clean.sh          # Remove all build artifacts
./scripts/build_all.sh      # Rebuild from scratch
```

## Build Pipeline Stages

1. **Pilot Study** (`01_run_pilot.sh`): Quick sanity check (~1 minute)
   - Tests subset of methods on simple test cases
   - Output: `build/results/pilot/*.json`

2. **Comprehensive Study** (`02_run_comprehensive.sh`): Full benchmark (~7-10 minutes)
   - All methods √ó all noise levels √ó all derivative orders √ó multiple trials
   - Output: `build/results/comprehensive/comprehensive_summary.csv` ‚≠ê

3. **Generate Figures** (`03_generate_figures.sh`): Create all plots (~30 seconds)
   - Per-method heatmaps (noise √ó order)
   - Per-method line plots (noise sensitivity)
   - Per-order comparison plots (method rankings)
   - Output: `build/figures/publication/*.pdf` (62 plots total)

4. **Generate Tables** (`04_generate_tables.sh`): Create LaTeX tables (~10 seconds)
   - Summary tables (best methods per order)
   - Performance ranking tables
   - Method comparison matrices
   - Output: `build/tables/publication/*.tex`

5. **Compile Paper** (`05_compile_paper.sh`): Build final PDF (~20 seconds)
   - Includes auto-generated tables and figures
   - Output: `build/paper/paper.pdf` üìÑ

## Environment Setup

### Julia Dependencies
```bash
julia --project=. -e 'using Pkg; Pkg.instantiate()'
```

### Python Dependencies
```bash
uv sync                    # Using UV package manager
# OR
pip install -r requirements.lock
```

## Common Tasks

### Clean build and regenerate everything
```bash
./scripts/clean.sh && ./scripts/build_all.sh
```

### Quick edit-compile-view cycle for paper
```bash
vim report/sections/section6_results.tex
./scripts/05_compile_paper.sh
xdg-open build/paper/paper.pdf  # Linux
# open build/paper/paper.pdf    # macOS
```

### Re-run study after method changes
```bash
./scripts/02_run_comprehensive.sh  # Re-generate data
./scripts/03_generate_figures.sh   # Re-generate plots
./scripts/04_generate_tables.sh    # Re-generate tables
./scripts/05_compile_paper.sh      # Re-build paper
```

### Check what's been built
```bash
ls -R build/
```
